import streamlit as st
import os
import tempfile
import hashlib
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_community.document_loaders import (
    PyPDFLoader,
    Docx2txtLoader,
    TextLoader
)
from langchain.text_splitter import RecursiveCharacterTextSplitter

# --- UI ë° ì–¸ì–´ ì„¤ì • ---

# st.set_page_configëŠ” ê°€ì¥ ë¨¼ì € í˜¸ì¶œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
st.set_page_config(page_title="AI ë…¼ë¬¸ ë¶„ì„ Q&A", layout="wide")

# ë‹¤êµ­ì–´ ì§€ì› í…ìŠ¤íŠ¸
LANGUAGES = {
    "í•œêµ­ì–´": "ko",
    "English": "en"
}
ANSWER_LANGUAGES = {
    "Auto/ë¬¸ì„œ ê¸°ì¤€": "auto",
    "í•œêµ­ì–´": "Korean",
    "English": "English"
}

def get_ui_labels(lang_code):
    if lang_code == "en":
        return {
            "title": "ğŸ“„ AI Paper Analysis & Q&A",
            "upload_header": "1. Upload Paper",
            "file_uploader": "Select a file (PDF, DOCX, TXT)",
            "analyze_btn": "Start Analysis",
            "analyzing": "Analyzing the paper...",
            "analyze_success": "Paper analysis completed! You can now ask questions.",
            "analyze_error": "Error during analysis:",
            "upload_first": "Please upload a file first.",
            "ask_header": "2. Ask Questions about the Paper",
            "ask_placeholder": "e.g., What are the main contributions of this paper?",
            "wait_answer": "Generating answer with ChatGPT...",
            "answer_header": "### ğŸ¤– ChatGPT Answer",
            "answer_error": "Error during answer generation:",
            "need_upload": "Please upload a paper in the sidebar and click 'Start Analysis'.",
            "history_header": "Q&A History",
            "already_analyzed": "This paper has already been analyzed."
        }
    else: # í•œêµ­ì–´
        return {
            "title": "ğŸ“„ AI ë…¼ë¬¸ ë¶„ì„ ë° Q&A",
            "upload_header": "1. ë…¼ë¬¸ ì—…ë¡œë“œ",
            "file_uploader": "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš” (PDF, DOCX, TXT)",
            "analyze_btn": "ë…¼ë¬¸ ë¶„ì„ ì‹œì‘",
            "analyzing": "ë…¼ë¬¸ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ ì¶”ì¶œ, ë¶„í• , ì„ë² ë”© ê³¼ì •ì´ ì§„í–‰ë©ë‹ˆë‹¤...",
            "analyze_success": "ë…¼ë¬¸ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "analyze_error": "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:",
            "upload_first": "ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.",
            "ask_header": "2. ë…¼ë¬¸ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê¸°",
            "ask_placeholder": "ì˜ˆ: ì´ ë…¼ë¬¸ì˜ ì£¼ìš” ê¸°ì—¬ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "wait_answer": "ChatGPTê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...",
            "answer_header": "### ğŸ¤– ChatGPT ë‹µë³€",
            "answer_error": "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ:",
            "need_upload": "ì‚¬ì´ë“œë°”ì—ì„œ ë…¼ë¬¸ì„ ì—…ë¡œë“œí•˜ê³  'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.",
            "history_header": "Q&A ê¸°ë¡",
            "already_analyzed": "ì´ë¯¸ ë¶„ì„ëœ ë…¼ë¬¸ì…ë‹ˆë‹¤."
        }

# --- í•¨ìˆ˜ ì •ì˜ ---

def file_hash(fileobj):
    return hashlib.md5(fileobj.getvalue()).hexdigest()

# ë‹¤ì–‘í•œ ë¬¸ì„œ í˜•ì‹ ì§€ì› (ìˆ˜ì • ì—†ìŒ)
def get_text_from_doc(doc_file):
    suffix = os.path.splitext(doc_file.name)[-1].lower()
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:
        tmp_file.write(doc_file.getvalue())
        tmp_file_path = tmp_file.name

    try:
        if suffix == ".pdf":
            loader = PyPDFLoader(tmp_file_path)
        elif suffix == ".docx":
            loader = Docx2txtLoader(tmp_file_path)
        elif suffix == ".txt":
            # UTF-8 ì¸ì½”ë”©ì„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•˜ì—¬ ì˜¤ë¥˜ ë°©ì§€
            loader = TextLoader(tmp_file_path, encoding='utf-8')
        else:
            raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: PDF, DOCX, TXTë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
        
        pages = loader.load_and_split()
        text = " ".join(t.page_content for t in pages)
    finally:
        os.remove(tmp_file_path)
    return text

# QA ì²´ì¸ ìƒì„± í•¨ìˆ˜ (í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©)
def create_qa_chain(text, answer_language):
    # í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
    chunks = text_splitter.split_text(text)
    
    # ì„ë² ë”© ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    embeddings = OpenAIEmbeddings(openai_api_key=st.secrets["OPENAI_API_KEY"])
    vector_store = FAISS.from_texts(chunks, embeddings)

    # ë‹µë³€ ì–¸ì–´ì— ë”°ë¥¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    prompt_template = """
    Use the following pieces of context to answer the question at the end. 
    If you don't know the answer, just say that you don't know, don't try to make up an answer.
    
    {context}
    
    Question: {question}
    """
    if answer_language != "auto":
        prompt_template += f"\nHelpful Answer (MUST be in {answer_language}):"
    else:
        prompt_template += "\nHelpful Answer:"

    PROMPT = PromptTemplate(
        template=prompt_template, input_variables=["context", "question"]
    )

    # ChatGPT ëª¨ë¸ ì§€ì •
    llm = ChatOpenAI(
        model_name="gpt-4o",
        temperature=0.7,
        openai_api_key=st.secrets["OPENAI_API_KEY"]
    )
    
    # RetrievalQA ì²´ì¸ ìƒì„± (chain_type_kwargs ì‚¬ìš©)
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vector_store.as_retriever(),
        chain_type_kwargs={"prompt": PROMPT}
    )
    return qa_chain

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "qa_chain" not in st.session_state:
    st.session_state.qa_chain = None
if "history" not in st.session_state:
    st.session_state.history = []
if "analyzed_filename" not in st.session_state:
    st.session_state.analyzed_filename = None
if "analyzed_filehash" not in st.session_state:
    st.session_state.analyzed_filehash = None
if "language" not in st.session_state:
    st.session_state.language = "ko"
if "answer_language" not in st.session_state:
    st.session_state.answer_language = "auto"

# --- ì‚¬ì´ë“œë°” UI ---
with st.sidebar:
    # ì–¸ì–´ ì„ íƒ
    selected_lang_key = st.selectbox(
        "ğŸŒ ì–¸ì–´ (Language/UI)",
        options=list(LANGUAGES.keys()),
        index=list(LANGUAGES.values()).index(st.session_state.language)
    )
    st.session_state.language = LANGUAGES[selected_lang_key]
    labels = get_ui_labels(st.session_state.language)

    # ë‹µë³€ ì–¸ì–´ ì„ íƒ
    selected_ans_lang_key = st.selectbox(
        "ğŸ¤– ë‹µë³€ ì–¸ì–´ (Answer Language)",
        options=list(ANSWER_LANGUAGES.keys()),
        index=list(ANSWER_LANGUAGES.values()).index(st.session_state.answer_language)
    )
    st.session_state.answer_language = ANSWER_LANGUAGES[selected_ans_lang_key]

    st.markdown("---")
    st.header(labels["upload_header"])
    uploaded_file = st.file_uploader(
        labels["file_uploader"],
        type=['pdf', 'docx', 'txt']
    )

    if st.button(labels["analyze_btn"]):
        if uploaded_file is not None:
            this_hash = file_hash(uploaded_file)
            # íŒŒì¼ì´ ë³€ê²½ë˜ì—ˆì„ ë•Œë§Œ ìƒˆë¡œ ë¶„ì„
            if this_hash != st.session_state.analyzed_filehash:
                with st.spinner(labels["analyzing"]):
                    try:
                        extracted_text = get_text_from_doc(uploaded_file)
                        st.session_state.qa_chain = create_qa_chain(
                            extracted_text, st.session_state.answer_language
                        )
                        st.session_state.analyzed_filename = uploaded_file.name
                        st.session_state.analyzed_filehash = this_hash
                        st.session_state.history = [] # ìƒˆ ë…¼ë¬¸ì´ë¯€ë¡œ ê¸°ë¡ ì´ˆê¸°í™”
                        st.success(labels["analyze_success"])
                    except Exception as e:
                        st.error(f"{labels['analyze_error']} {e}")
            else:
                st.info(labels["already_analyzed"])
        else:
            st.warning(labels["upload_first"])

# --- ë©”ì¸ í™”ë©´ UI ---
st.title(labels["title"])
st.markdown("---")

if st.session_state.qa_chain is None:
    st.info(labels["need_upload"])
else:
    st.header(labels["ask_header"])
    file_display_name = st.session_state.analyzed_filename or "íŒŒì¼ ì—†ìŒ"
    query = st.text_input(
        f"'{file_display_name}'ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê¸°",
        placeholder=labels["ask_placeholder"],
        key="query_input"
    )

    if query:
        with st.spinner(labels["wait_answer"]):
            try:
                response = st.session_state.qa_chain.invoke(query)
                answer = response['result']
                st.session_state.history.append({"question": query, "answer": answer})
            except Exception as e:
                st.error(f"{labels['answer_error']} {e}")
                st.session_state.history.append({"question": query, "answer": f"Error: {e}"})

    # Q&A ê¸°ë¡ í‘œì‹œ (expanderë¡œ ì ‘ê¸° ê¸°ëŠ¥)
    if st.session_state.history:
        st.markdown("---")
        st.subheader(labels["history_header"])
        for idx, qa in enumerate(reversed(st.session_state.history), 1):
            with st.expander(f"Q{idx}: {qa['question']}"):
                st.markdown(f"**A:** {qa['answer']}")
