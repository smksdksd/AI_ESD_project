import streamlit as st
import os
import tempfile
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# --- í•¨ìˆ˜ ì •ì˜ ---

# ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
def get_text_from_doc(doc_file):
    # Streamlitì˜ UploadedFile ê°ì²´ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(doc_file.getvalue())
        tmp_file_path = tmp_file.name

    # PyPDFLoaderë¥¼ ì‚¬ìš©í•˜ì—¬ PDF íŒŒì¼ ë¡œë“œ
    # (docx, txt ë“± ë‹¤ë¥¸ í˜•ì‹ ì§€ì›ì„ ì›í•˜ì‹œë©´ ì—¬ê¸°ì— ë¡œì§ì„ ì¶”ê°€í•˜ì„¸ìš”)
    loader = PyPDFLoader(tmp_file_path)
    pages = loader.load_and_split()
    text = " ".join(t.page_content for t in pages)
    
    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    os.remove(tmp_file_path)
    return text

# í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ QA ì²´ì¸ì„ ìƒì„±í•˜ê³  ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
def create_qa_chain(text):
    # 1. í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1500,  # ì²­í¬ í¬ê¸°ë¥¼ ì¡°ê¸ˆ ë” í¬ê²Œ ì„¤ì •
        chunk_overlap=200,
        length_function=len
    )
    chunks = text_splitter.split_text(text)

    # 2. OpenAI ì„ë² ë”© ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
    # st.secretsë¥¼ í†µí•´ ì•ˆì „í•˜ê²Œ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    embeddings = OpenAIEmbeddings(openai_api_key=st.secrets["OPENAI_API_KEY"])
    
    # 3. FAISS ë²¡í„° ìŠ¤í† ì–´ì— ë²¡í„°í™”ëœ í…ìŠ¤íŠ¸ ì €ì¥
    vector_store = FAISS.from_texts(chunks, embeddings)

    # 4. ChatGPT ëª¨ë¸ ì§€ì • (gpt-4o ë˜ëŠ” gpt-3.5-turbo ë“±)
    llm = ChatOpenAI(
        model_name="gpt-4o", 
        temperature=0.7, # ì°½ì˜ì ì¸ ë‹µë³€ì´ í•„ìš”í•˜ë©´ ì˜¨ë„ë¥¼ ë†’ì„
        openai_api_key=st.secrets["OPENAI_API_KEY"]
    )
    
    # 5. Langchainì˜ RetrievalQA ì²´ì¸ ìƒì„±
    # retrieverëŠ” ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff", # ê°€ì¥ ì¼ë°˜ì ì¸ ì²´ì¸ íƒ€ì…
        retriever=vector_store.as_retriever()
    )
    return qa_chain

# --- Streamlit UI êµ¬ì„± ---

st.set_page_config(page_title="AI ë…¼ë¬¸ ë¶„ì„ Q&A", layout="wide")
st.title("ğŸ“„ AI ë…¼ë¬¸ ë¶„ì„ ë° Q&A")
st.markdown("---")

# ì„¸ì…˜ ìƒíƒœ(session_state) ì´ˆê¸°í™”
if "qa_chain" not in st.session_state:
    st.session_state.qa_chain = None

# ì‚¬ì´ë“œë°” UI
with st.sidebar:
    st.header("1. ë…¼ë¬¸ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader(
        "PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.", 
        type=['pdf']
    )
    
    if st.button("ë…¼ë¬¸ ë¶„ì„ ì‹œì‘"):
        if uploaded_file is not None:
            with st.spinner('ë…¼ë¬¸ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ ì¶”ì¶œ, ë¶„í• , ì„ë² ë”© ê³¼ì •ì´ ì§„í–‰ë©ë‹ˆë‹¤...'):
                try:
                    extracted_text = get_text_from_doc(uploaded_file)
                    st.session_state.qa_chain = create_qa_chain(extracted_text)
                    st.success("ë…¼ë¬¸ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            st.warning("ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

# ë©”ì¸ í™”ë©´ UI
st.header("2. ë…¼ë¬¸ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê¸°")

if st.session_state.qa_chain is None:
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ ë…¼ë¬¸ì„ ì—…ë¡œë“œí•˜ê³  'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
else:
    query = st.text_input(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", 
        placeholder="ì˜ˆ: ì´ ë…¼ë¬¸ì˜ ì£¼ìš” ê¸°ì—¬ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        key="query_input"
    )
    
    if query:
        with st.spinner("ChatGPTê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                response = st.session_state.qa_chain.invoke(query)
                st.markdown("### ğŸ¤– ChatGPT ë‹µë³€")
                st.write(response['result'])
            except Exception as e:
                st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
