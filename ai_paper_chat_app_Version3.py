import streamlit as st
import openai
import fitz  # PyMuPDF
import docx
import io

# API í‚¤ ì„¤ì •
if "OPENAI_API_KEY" in st.secrets:
    openai.api_key = st.secrets["OPENAI_API_KEY"]
elif "OPENAI_API_KEY" in st.session_state:
    openai.api_key = st.session_state["OPENAI_API_KEY"]
else:
    st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. secrets.tomlì´ë‚˜ í™˜ê²½ë³€ìˆ˜ì— í‚¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
def extract_text(file):
    file_bytes = file.read()  # íŒŒì¼ì„ í•œ ë²ˆë§Œ ì½ìŒ
    file_buffer = io.BytesIO(file_bytes)  # BytesIOë¡œ ê°ì‹¸ì„œ ì—¬ëŸ¬ ë²ˆ ì‚¬ìš© ê°€ëŠ¥
    file_name = file.name.lower()

    if file_name.endswith(".pdf"):
        return extract_from_pdf(file_buffer)
    elif file_name.endswith(".docx"):
        return extract_from_docx(file_buffer)
    elif file_name.endswith(".txt"):
        # í…ìŠ¤íŠ¸ íŒŒì¼ì€ ì›ë³¸ ë°”ì´ë„ˆë¦¬ë¥¼ utf-8ë¡œ ë””ì½”ë”©
        return file_bytes.decode("utf-8")
    else:
        return "ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."

def extract_from_pdf(file_buffer):
    file_buffer.seek(0)
    doc = fitz.open(stream=file_buffer.read(), filetype="pdf")
    text = ""
    for page in doc:
        text += page.get_text()
    return text

def extract_from_docx(file_buffer):
    file_buffer.seek(0)
    doc = docx.Document(file_buffer)
    return "\n".join([para.text for para in doc.paragraphs])

# GPT ìš”ì•½ ë° ì§ˆì˜ì‘ë‹µ í•¨ìˆ˜
def ask_question_to_ai(context_text, user_question, chat_history=None):
    if chat_history is None:
        chat_history = []
    messages = [{"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìì˜ ë…¼ë¬¸ì„ ìš”ì•½í•˜ê³ , ì§ˆë¬¸ì— ì‘ë‹µí•˜ëŠ” ì¹œì ˆí•œ AIì•¼."}]
    messages += chat_history
    messages.append({"role": "user", "content": f"ë…¼ë¬¸ ë‚´ìš©:\n{context_text[:3000]}\n\nì§ˆë¬¸: {user_question}"})

    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=messages,
        max_tokens=600,
        temperature=0.3
    )

    reply = response.choices[0].message["content"]
    chat_history.append({"role": "user", "content": user_question})
    chat_history.append({"role": "assistant", "content": reply})
    return reply, chat_history

# Streamlit UI
st.set_page_config(page_title="ë…¼ë¬¸ ìš”ì•½ & QnA", page_icon="ğŸ“„", layout="wide")
st.title("ğŸ“„ AI ë…¼ë¬¸ ìš”ì•½ ë° ì§ˆì˜ì‘ë‹µ ì„œë¹„ìŠ¤")
st.write("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸í•˜ë©´ AIê°€ ìš”ì•½í•˜ê³  ëŒ€ë‹µí•´ì¤ë‹ˆë‹¤.")

uploaded_file = st.file_uploader("ë…¼ë¬¸ íŒŒì¼ ì—…ë¡œë“œ (PDF, DOCX, TXT ì§€ì›)", type=["pdf", "docx", "txt"])
if uploaded_file:
    with st.spinner("ë¬¸ì„œ ì²˜ë¦¬ ì¤‘..."):
        doc_text = extract_text(uploaded_file)
        st.session_state["doc_text"] = doc_text
        st.success("ë¬¸ì„œ ì—…ë¡œë“œ ë° ì²˜ë¦¬ ì™„ë£Œ!")

# ëŒ€í™” ê¸°ë¡ ì €ì¥
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

# ì±„íŒ… ì…ë ¥
if "doc_text" in st.session_state:
    user_input = st.chat_input("ë…¼ë¬¸ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
    if user_input:
        with st.spinner("AIê°€ ì‘ë‹µ ì¤‘ì…ë‹ˆë‹¤..."):
            reply, updated_history = ask_question_to_ai(
                st.session_state["doc_text"], user_input, st.session_state["chat_history"]
            )
            st.session_state["chat_history"] = updated_history
            st.chat_message("user").write(user_input)
            st.chat_message("assistant").write(reply)